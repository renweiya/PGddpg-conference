max_step_before_punishment	8
plot_reward_recent_mean	1000
prioritized_er	False
inc_or_dec_step	1000
target_update_interval	1
learning	True
state_action_confidence_max	1.0
batch_size	1024
consider_state_action_confidence	True
h_layer_num	2
exp_name	3v1_easy_reward
positive_buffer_size	32
prey_policy	ddpg
reload_prey	True
beta	0.4
gan_batch_size	8
buffer_size	300000
n_train_repeat	1
prey_model_path	./exp_result/prey/model-prey-s
return_confidence_factor	0.7
train_prey	False
ddpg_qlr	0.001
num_units	128
render	False
gamma	0.99
state_action_confidence	0.8
tau	0.01
lambda1_max	1.0
episodes	500000
gradually_inc_within_episode	12000
save_checkpoint_every_epoch	2000
imitation_lambda_max	1.0
d_lr	0.001
predator_policy	ddpg
lambda2	1e-06
num_adversaries	3
alpha	0.6
gradually_inc_start_episode	0
save_return	True
lambda1	0.0
train_discriminator_k	1
predator_model_path	./exp_result/round_up/pre_train_prey/saved_models/seed_ddpg_81/model-87000
env_name	round_up_reward_easy_reward
rlpl_beta	0.5
imitation_lambda	0.0
reload_predator	False
num_good_agents	1
min_positive_buffer_size	32
seed	1
learning_curve_dir	./exp_result/3v1_easy_reward/learning_curves/round_up_reward_easy_reward/seed_ddpg/20200913233758
ddpg_plr	0.01
num_units_ma	256
max_episode_len	200
model_save_dir	./exp_result/3v1_easy_reward/saved_models/round_up_reward_easy_reward/seed_ddpg/20200913233758/model
tensorboard_dir	./exp_result/3v1_easy_reward/tensorboard_dir/round_up_reward_easy_reward/seed_ddpg/20200913233758
min_buffer_size	30000
